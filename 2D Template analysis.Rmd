---
title: "Template for 2D data analysis with INLABru"
author: "J Matthiopoulos (collated from INLABru vignettes)"
date: '2022-05-27'
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# I. Preparation

## I.1. Load libraries

```{r results="hide",warning=FALSE,message=FALSE}
# Essential
library(inlabru)
library(INLA)
bru_options_set(inla.mode = "experimental")

# Visualisation
library(ggplot2)
library(RColorBrewer)

# Loaded dependencies
#library(sp)
#library(Matrix)
#library(foreach)
#library(parallel)

# Optional
library(mgcv) # For independent model performance comparisons, used as an exact method


#library(sf)
#library(raster)
#library(rmapshaper)
#library(tidyr)


```
## I.2. Load data
In the example below, it is assumed that the data reside in a package, such as 'inlabru'. The 'try' option explores the list of available datasets. The second line loads the particular one. Other ways of importing the data, assuming they are not in a package ('?data') with option 'lib.loc' for pathname. 

```{r eval=FALSE}
#try(data(package="inlabru"))
data(gorillas, package = "inlabru")
```

## I.3. Ensure data formatting

The overall structure of the data can be explored by 'str()'. The point locations (here, 'nests') need to be a 'SpatialPointsDataFrame'. If the point data are not in this form then, they will need to be converted by providing an appropriate spatial projection ('?SpatialPointsDataFrame').

```{r eval=FALSE}
#str(gorillas)
#str(gorillas$nests)
myPoints<-gorillas$nests # assign to shorthand
myCovs <- gorillas$gcov # Covariate data
```
If the data set comes with in-built mesh and boundary components, then proceed to I.5, otherwise specify the mesh in the next section. 

```{r eval=FALSE}
#str(gorillas$mesh)
#str(gorillas$boundary)
myMesh<-gorillas$mesh # assign to shorthand
myBoundary<-gorillas$boundary # assign to shorthand
```
Visualise the factor covariate data (`vegetation` type)

```{r eval=FALSE, warning=FALSE, message=FALSE}
ggplot() +
  gg(myCovs$vegetation) +
  gg(myMesh) +
  gg(myBoundary) +
  gg(myPoints, color = "white", cex = 0.5) +
  coord_equal()
```



# II. GLMs

## II.1 A GLM with a factor covariate only

-----> Preparation of factor coavariate layer on a mesh is likely to be challenging. Most data layers will come in raster form and while the projection to a mesh is easy for continuous variables (e.g., pixel_n <- raster(spatialpixeldf)), this is not straight forward with factors. Of course, in the data above this comes pre-made. 

To construct a model with vegetation type as a fixed effect, we need to tell 'lgcp' how to find the vegetation type at any point in space, and we do this by creating model components with a fixed effect that we call `vegetation` (we could call it anything), as follows:


```{r eval=FALSE, warning=FALSE,message=FALSE}
myFactComp <- coordinates ~ vegetation(myCovs$vegetation, model = "factor_full") - 1
```

Notes:

* We need to tell 'lgcp' that this is a factor fixed effect, which we do 
with `model="factor_full"`, giving one coefficient for each factor level.
* We need to be careful about overparameterisation when using factors.
Unlike regression models like `lm()`, `glm()` or `gam()`, `lgcp()`,
`inlabru` does not automatically remove the first level and absorb it into
an intercept. Instead, we can either use `model="factor_full"` without an intercept,
or `model="factor_contrast"`, which does remove the first level.

```{r eval=FALSE, warning=FALSE,message=FALSE}
myFactCompAlt <- coordinates ~ vegetation(myCovs$vegetation, model = "factor_contrast") + Intercept(1)
```
The model can be fitted as follows

```{r eval=FALSE, results='hide',warning=FALSE,message=FALSE,eval=FALSE}
myFactorGLM <- lgcp(myFactComp, myPoints, samplers = myBoundary, domain = list(coordinates = myMesh))
```


Predict the intensity, and plot the median intensity surface. The `predidct` function of `inlabru` takes into its `data` argument a `SpatialPointsDataFrame`, 
a `SpatialPixelsDataFrame` or a `data.frame`. We can use the `inlabru` function `pixels` to generate
a `SpatialPixelsDataFrame` only within the boundary, using its `mask` argument, as shown below.


```{r eval=FALSE, warning=FALSE,message=FALSE}
df <- pixels(myMesh, mask = myBoundary)
int1 <- predict(myFactorGLM, data = df, ~ exp(vegetation))
ggplot() +
  gg(int1) +
  gg(myBoundary, alpha = 0, lwd = 2) +
  gg(myPoints, color = "DarkGreen") +
  coord_equal()
```

The estimated total abundance of points (but not full posterior) can be obtained as follows.The integration `weight` values (the quadrature points) are contained in the `ipoints` output.

```{r eval=FALSE, warning=FALSE,message=FALSE}
ips <- ipoints(myBoundary, myMesh)
Lambda1 <- predict(myFactorGLM, ips, ~ sum(weight * exp(vegetation)))
Lambda1
```
## II.1 A GLM with a continuous covariate only

# III. SPDE model, no covariates

## III.1. Build the SPDE mesh 
For this section I will ignore the fact that the gorillas data set comes with a predefined mesh and develop one from scratch.
There are several arguments that can be used to build the mesh. The arguments for a two-dimensional mesh construction are the following:

```{r message=FALSE, warning=FALSE}
args(inla.mesh.2d)
```

First, some reference about the study region is needed, which can be provided by either:

1. The location of points, supplied on the `loc` argument ^[Matrix of point locations to be used as initial triangulation nodes. Can alternatively be a `SpatialPoints` or `SpatialPointsDataFrame` object.].
2.  A boundary of the region defined by a set of polygons (e.g., a polygon defining the coastline of the study) supplied on the `boundary` argument.
3.  The domain extent which can be supplied as a single polygon on the `loc.domain` argument.


Note that if either (1) the location of points or (3) the domain extent are specified, the mesh will be constructed based on a convex hull (a polygon of triangles out of the domain area). Alternatively, it is possible to include a non-convex hull as a boundary in the mesh construction instead of the `loc` or `loc.domain` arguments. This will result in the triangulation to be constrained by the boundary. A non-convex hull mesh can also be created by building a boundary for the points using the `inla.nonconvex.hull()` function. Finally, the other compulsory argument that needs to be specified is `max.edge` which determines the largest allowed triangle length (the lower the value for max.edge the higher the resolution). The value supplied to this argument can be either a scalar, in which case the value controls the triangle edge lengths in the inner domain, or a length two vector that controls the edge lengths in the inner domain and in the outer extension respectively. Notice that The value (or values) passed to the `max.edge` option must be on the same scale unit as the coordinates. 

While there is no general rule for setting a correct value for the `max.edge`, a value for `max.edge` that is too close to the spatial range will make the task of fitting a smooth SPDE difficult. On the other hand, if the `max.edge` value is too small compared to the spatial range, the mesh will have a large number of vertices leading to a more computationally demanding fitting process (which might not necessarily lead to better results). Thus, it is better to begin the analysis with a coarse matrix and evaluate the model on a finer grid as a final step. The `cutoff` option regulates the minimum length of each edge (could have been called "min.edge", more intuitively?).

I first develop the mesh by using the boundary of the study area.

```{r eval=FALSE, message=FALSE, warning=FALSE}
# Build the mesh
bbox<-bbox(myBoundary)
max.edge <- 1/20*sqrt((bbox[1,1]-bbox[1,2])^2+(bbox[2,1]-bbox[2,2])^2)

myMesh <- inla.mesh.2d(boundary = myBoundary,
                    max.edge = max.edge,
                    cutoff=.1)

#plot(mesh)

ggplot() +
     gg(data=myBoundary,color='turquoise',fill='transparent')+  
  gg(myMesh)

```

We can also specify an outer layer with a lower triangle density (i.e. where no points occur) to avoid this boundary effect. This can be done by supplying a vector of two values so that the spatial domain is divided into an inner and an outer area. Here, we will define the max.edge such that the outer layer will have a triangle density two times lower than than the inner layer (i.e. twice the length for the outer layer edges).The amount to which the domain should be extended in the inner and outer part can be controlled with the offset argument of the inla.mesh.2d function. For this example we will expand the inner layer by the same amount as the max.edge and the outer layer by the range we assumed when defining the inner max.edge value (i.e. 1/4 of the spatial extent).

```{r eval=FALSE,message=FALSE, warning=FALSE}
# Build the mesh
bbox<-bbox(myBoundary)
max.edge <- 1/20*sqrt((bbox[1,1]-bbox[1,2])^2+(bbox[2,1]-bbox[2,2])^2)
bound.outer <- 1/4*sqrt((bbox[1,1]-bbox[1,2])^2+(bbox[2,1]-bbox[2,2])^2)

myMesh <- inla.mesh.2d(boundary = myBoundary,
                    max.edge = c(1,2)*max.edge,
                    cutoff=.1,
                    offset=c(max.edge, bound.outer))

#plot(mesh)

ggplot() +
     gg(data=myBoundary,color='turquoise',fill='transparent')+  
  gg(myMesh)

```

Plot the points (the nests(. (The `ggplot2` function `coord_fixed()` sets the aspect ratio, 
which defaults to 1.)

```{r eval=FALSE, results="hide",warning=FALSE,message=FALSE}
ggplot() +
  gg(myMesh) +
  gg(myPoints) +
  gg(myBoundary) +
  coord_fixed() +
  ggtitle("Points")
```

## III.2. The model

First, specify spatial correlation structure. The following is an example using a Matern correlation structure with a PC prior.

```{r eval=FALSE}
myCorrelation<-inla.spde2.pcmatern(myMesh, prior.range = c(5, 0.01), prior.sigma = c(0.1, 0.01))
  
```

Then, define the model. The model formula requires the explicit name 'coordinates' to recognise the mesh information that it will receive later, but can use the user-defined 'mySmooth()' to specify the spatial error term.  

```{r eval=FALSE}

mySpdeComp<-coordinates~mySmooth(coordinates, model=myCorrelation) + Intercept(1)
  
```
The `lcgp` models is fitted as follows:
 

```{r eval=FALSE, warning=FALSE, message=FALSE}

mySpdeFit<-lgcp(mySpdeComp, data=myPoints, samplers=myBoundary, domain=list(coordinates=myMesh))
  
```
Summary statistics:

```{r eval=FALSE,warning=FALSE,message=FALSE}
summary(mySpdeFit)
```

## III.3 Inference 

Plotting fixed effect parameters

```{r eval=FALSE,warning=FALSE,message=FALSE}
plot(mySpdeFit, "Intercept")
```

Plotting spatial random effects
Plots of the individual parameters

```{r eval=FALSE,warning=FALSE,message=FALSE}
spde.range <- spde.posterior(mySpdeFit, "mySmooth", what = "range")
spde.logvar <- spde.posterior(mySpdeFit, "mySmooth", what = "log.variance")
range.plot <- plot(spde.range)
var.plot <- plot(spde.logvar)
multiplot(range.plot, var.plot)
```

Plots of the correlation and covariance functions

```{r eval=FALSE,warning=FALSE,message=FALSE}
corplot <- plot(spde.posterior(mySpdeFit, "mySmooth", what = "matern.correlation"))
covplot <- plot(spde.posterior(mySpdeFit, "mySmooth", what = "matern.covariance"))
multiplot(covplot, corplot)
```

## III.4 Model predictions

First need to generate the prediction data frame. The 'pixels()' command generates a regular grid of points which can be used for the prediction. This is stored as a spatial data frame in the user-defined 'myPredFrame'. 

```{r eval=FALSE, warning=FALSE, message=FALSE}

myPredFrame<-pixels(myMesh, nx = 50, ny = 50, mask = FALSE)
  
```
To constrain the predictions to a particular region (e.g. the boundary of the mesh), set the mask option in the 'pixels()' command to 'mask=myBoundary'.

Now we can generate the predictions.


```{r eval=FALSE, warning=FALSE, message=FALSE}

myPreds<-predict(mySpdeFit, myPredFrame,~ exp(mySmooth + Intercept))
  
```
Note that multiple functions and linear predictors can be predicted simultaneously, under different names.

```{r eval=FALSE, warning=FALSE, message=FALSE}
myPreds<-predict(mySpdeFit, myPredFrame,  
                 ~ data.frame(myLambda = exp(mySmooth + Intercept),
                              myLoglambda = mySmooth + Intercept)
                )
  
```

We can visualize multiple aspects of the predictions

Plotting intensity and log-intensity surfaces

```{r eval=FALSE, warning=FALSE, message=FALSE}
pl1 <- ggplot() +
  gg(myPreds$myLambda) +
  gg(myBoundary) +
  ggtitle("LGCP fit to Points", subtitle = "(Response Scale)") +
  coord_fixed()
pl2 <- ggplot() +
  gg(myPreds$myLoglambda) +
  gg(myBoundary) +
  ggtitle("LGCP fit to Points", subtitle = "(Linear Predictor Scale)") +
  coord_fixed()
multiplot(pl1, pl2, cols = 2)
```

Alternatively, plotting maps of median, lower 95% and upper 95% density surfaces as follows (assuming that the predicted intensity is in object `myLambda`).

```{r eval=FALSE,warning=FALSE,message=FALSE,fig.width=9,fig.height=4}
ggplot() +
  gg(cbind(myPreds$myLambda, data.frame(property = "q0.500")), aes(fill = median)) +
  gg(cbind(myPreds$myLambda, data.frame(property = "q0.025")), aes(fill = q0.025)) +
  gg(cbind(myPreds$myLambda, data.frame(property = "q0.975")), aes(fill = q0.975)) +
  coord_equal() +
  facet_wrap(~property)
```


## III.5 Estimating abundance

Estimating abundance uses the `predict` function. As a first step we need an estimate
 for the integrated lambda (denoted 'Lambda' with an upper case L). The integration `weight` values (the quadrature points) are contained in the `ipoints` output. 
 

```{r eval=FALSE,warning=FALSE,message=FALSE,echo=TRUE}
Lambda <- predict(
  mySpdeFit,
  ipoints(myBoundary, myMesh),
  ~ sum(weight * exp(mySmooth + Intercept))
)
Lambda
```


Use the median and 95%iles of this to determine interval boundaries for estimating the posterior abundance distribution (prediction, not credible interval).

```{r eval=FALSE,warning=FALSE,message=FALSE,echo=TRUE}
abundance <- predict(
  mySpdeFit, ipoints(myBoundary, myMesh),
  ~ data.frame(
    N = 500:800,
    dpois(500:800,
      lambda = sum(weight * exp(mySmooth + Intercept))
    )
  )
)
```

Can get the quantiles of the posterior for abundance via

```{r eval=FALSE, warning=FALSE,message=FALSE,echo=TRUE}
inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x = abundance$N, y = abundance$mean))
```
... the mean via
```{r eval=FALSE, warning=FALSE,message=FALSE,echo=TRUE}
inla.emarginal(identity, marginal = list(x = abundance$N, y = abundance$mean))
```
and plot posteriors:
```{r eval=FALSE, results="hide",warning=FALSE,message=FALSE,echo=TRUE}
abundance$plugin_estimate <- dpois(abundance$N, lambda = Lambda$mean)
ggplot(data = abundance) +
  geom_line(aes(x = N, y = mean, colour = "Posterior")) +
  geom_line(aes(x = N, y = plugin_estimate, colour = "Plugin"))
```

# IV. Factor GLM with SPDE spatial term
This will borrow the same (Matern) correlation structure as defined in part III above `myCorrelation`. The combined model is defined as follows. Note the removal of the intercept under the factor model 'factor_full'. 

```{r eval=FALSE, results='hide',warning=FALSE,message=FALSE}
mySpdeGlmComp <- coordinates ~
-1 +vegetation(myCovs$vegetation, model = "factor_full") +
  mySmooth(coordinates, model = myCorrelation)
```
Model is fitted:

```{r eval=FALSE, results='hide',warning=FALSE,message=FALSE,eval=FALSE}
fitSpdeGlm <- lgcp(mySpdeGlmComp, myPoints, samplers = myBoundary, domain = list(coordinates = myMesh))
```

Spatial plot of the fitted (median) intensity surface:
```{r eval=FALSE, warning=FALSE,message=FALSE}
df <- pixels(myMesh, mask = myBoundary)
int2 <- predict(fitSpdeGlm , df, ~ exp(mySmooth + vegetation), n.samples = 1000)
ggplot() +
  gg(int2, aes(fill = q0.025)) +
  gg(myBoundary, alpha = 0, lwd = 2) +
  gg(myPoints) +
  coord_equal()
```
... and the expected integrated intensity (mean of abundance)


```{r eval=FALSE, warning=FALSE,message=FALSE}
Lambda2 <- predict(
  fitSpdeGlm,
  ipoints(myBoundary, myMesh),
  ~ sum(weight * exp(mySmooth + vegetation))
)
Lambda2
```


To look at the contributions to the linear predictor from the SPDE and from vegetation, we can first generate predictions from those combined, and individually.

```{r eval=FALSE, warning=FALSE,message=FALSE}
lp2 <- predict(fitSpdeGlm, df, ~ list(
  smooth_veg = mySmooth + vegetation,
  smooth = mySmooth,
  veg = vegetation
))
```

The function `scale_fill_gradientn` sets the scale for the plot legend. Here, we set it to span the range of the three linear predictor components being plotted (medians are plotted by default).


```{r eval=FALSE, warning=FALSE,message=FALSE}
lprange <- range(lp2$smooth_veg$median, lp2$smooth$median, lp2$veg$median)
csc <- scale_fill_gradientn(colours = brewer.pal(9, "YlOrRd"), limits = lprange)
plot.lp2 <- ggplot() +
  gg(lp2$smooth_veg) +
  csc +
  theme(legend.position = "bottom") +
  gg(myBoundary, alpha = 0) +
  ggtitle("mySmooth + vegetation") +
  coord_equal()
plot.lp2.spde <- ggplot() +
  gg(lp2$smooth) +
  csc +
  theme(legend.position = "bottom") +
  gg(myBoundary, alpha = 0) +
  ggtitle("mySmooth") +
  coord_equal()
plot.lp2.veg <- ggplot() +
  gg(lp2$veg) +
  csc +
  theme(legend.position = "bottom") +
  gg(myBoundary, alpha = 0) +
  ggtitle("vegetation") +
  coord_equal()
multiplot(plot.lp2, plot.lp2.spde, plot.lp2.veg, cols = 3)
```